{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRVrvJ4W6Z-Q",
        "outputId": "8cce9b1e-4ada-449d-8fdc-38d90054051f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/rdsgpfs/general/project/aandedemand/live/satellite/junin/deforestation_forecasting/python_code/Notebooks'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFBGNZXD6Z-S"
      },
      "outputs": [],
      "source": [
        "class Conv_3D(torch.nn.Module):\n",
        "    def __init__(self, input_dim=(2,8),\n",
        "                 hidden_dim=(16,32,32),\n",
        "                 kernel_size=((5,5),(2,5,5),(5,5)),\n",
        "                 levels=(10,),\n",
        "                 dropout = 0.2):\n",
        "        super(Conv_3D, self).__init__()\n",
        "\n",
        "        self.levels = levels\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.conv_2D = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(input_dim[0],hidden_dim[0],kernel_size = kernel_size[0]),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm2d(hidden_dim[0]),\n",
        "\n",
        "            torch.nn.Conv2d(hidden_dim[0],hidden_dim[0],kernel_size = kernel_size[0]),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm2d(hidden_dim[0]))\n",
        "\n",
        "        self.conv_3D = torch.nn.Sequential(\n",
        "                        torch.nn.Conv3d(in_channels = input_dim[1],\n",
        "                                        out_channels = hidden_dim[1],\n",
        "                                        kernel_size = kernel_size[1]),\n",
        "                        torch.nn.ReLU(),\n",
        "                        torch.nn.BatchNorm3d(hidden_dim[1]),\n",
        "\n",
        "                        torch.nn.Conv3d(in_channels = hidden_dim[1],\n",
        "                                        out_channels = hidden_dim[1],\n",
        "                                        kernel_size = kernel_size[1]),\n",
        "                        torch.nn.ReLU(),\n",
        "                        torch.nn.BatchNorm3d(hidden_dim[1]))\n",
        "\n",
        "        self.final = torch.nn.Sequential(\n",
        "                        torch.nn.Conv2d(hidden_dim[0]+hidden_dim[1], hidden_dim[2], kernel_size[2]),\n",
        "                        torch.nn.ReLU(),\n",
        "                        torch.nn.BatchNorm2d(hidden_dim[2]),\n",
        "\n",
        "                        torch.nn.Conv2d(hidden_dim[2], hidden_dim[2], kernel_size[2]),\n",
        "                        torch.nn.ReLU(),\n",
        "                        torch.nn.BatchNorm2d(hidden_dim[2]),\n",
        "\n",
        "                        torch.nn.Conv2d(hidden_dim[2], hidden_dim[2], kernel_size[2]),\n",
        "                        torch.nn.ReLU(),\n",
        "                        torch.nn.BatchNorm2d(hidden_dim[2]),\n",
        "\n",
        "                        torch.nn.Conv2d(hidden_dim[2], hidden_dim[2], kernel_size[2]),\n",
        "                        torch.nn.ReLU(),\n",
        "                        torch.nn.BatchNorm2d(hidden_dim[2]),\n",
        "\n",
        "                        torch.nn.Conv2d(hidden_dim[2], hidden_dim[2], kernel_size[2]),\n",
        "                        torch.nn.ReLU(),\n",
        "                        torch.nn.BatchNorm2d(hidden_dim[2]),\n",
        "\n",
        "                        torch.nn.Conv2d(hidden_dim[2], hidden_dim[2], kernel_size[2]),\n",
        "                        torch.nn.ReLU(),\n",
        "                        torch.nn.BatchNorm2d(hidden_dim[2]))\n",
        "\n",
        "        ln_in = 0\n",
        "        for i in levels:\n",
        "            ln_in += hidden_dim[2]*i*i\n",
        "\n",
        "        self.ln = torch.nn.Sequential(\n",
        "            torch.nn.Linear(ln_in,100),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm1d(100),\n",
        "            torch.nn.Dropout(dropout),\n",
        "            torch.nn.Linear(100, 1))\n",
        "\n",
        "        self.sig = torch.nn.Sigmoid()\n",
        "\n",
        "\n",
        "    def forward(self, data , sigmoid = True ):\n",
        "\n",
        "        s , x = data\n",
        "\n",
        "        s = self.conv_2D.forward(s)\n",
        "        x = self.conv_3D.forward(x)\n",
        "        x = x.squeeze(dim = 2 )\n",
        "        x = torch.cat((x,s),dim = 1)\n",
        "        x = self.final.forward(x)\n",
        "        x = spp_layer(x, self.levels)\n",
        "        x= self.ln(x)\n",
        "        if sigmoid:\n",
        "            x = self.sig(x)\n",
        "\n",
        "        return x.flatten()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z60RFDyu6Z-S"
      },
      "source": [
        "# Initial parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiXqvpbC6Z-S"
      },
      "outputs": [],
      "source": [
        "#set image parameters\n",
        "size = 45\n",
        "#set model parameters for 3D_CNN\n",
        "input_dim= (2,8)\n",
        "hidden_dim=(16,32,32)\n",
        "kernel_size=((5,5),(2,5,5),(5,5))\n",
        "levels=(13,)\n",
        "dropout = 0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJ9GEj-Z6Z-T"
      },
      "outputs": [],
      "source": [
        "model = Conv_3D(\n",
        "    input_dim = input_dim,\n",
        "    hidden_dim = hidden_dim,\n",
        "    kernel_size= kernel_size,\n",
        "    levels=levels,\n",
        "    dropout = dropout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jp48w5YM6Z-T",
        "outputId": "8a614e9d-333c-4f3c-a9b3-6d5acb6afbf5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.5335, 0.4771], grad_fn=<AsStridedBackward>)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b, c1, c2, t, h, w = 3, 2, 8, 3, size, size\n",
        "s = torch.rand(2,c1,size,size)\n",
        "x = torch.rand(2,c2,t,size,size)\n",
        "data = (s,x)\n",
        "model(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MSj49LC6Z-T",
        "outputId": "1fd3783f-0c92-4c2d-f3b7-3918610ce800"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input image spatial size: (45, 45)\n",
            "Changes of the spatial size in the two branches (2D_cov and 3D_conv)\n",
            "\tLayer 1\n",
            "\tkernel_size:  (5, 5)\n",
            "\tSize after layer 1 is applied: [41 41]\n",
            "\n",
            "\tLayer 2\n",
            "\tkernel_size:  (5, 5)\n",
            "\tSize after layer 2 is applied: [37 37]\n",
            "\n",
            "Changes of the spatial size in the final brach:\n",
            "\tLayer 1\n",
            "\tkernel_size:  (5, 5)\n",
            "\tSize after layer 1 is applied: [33 33]\n",
            "\n",
            "\tLayer 2\n",
            "\tkernel_size:  (5, 5)\n",
            "\tSize after layer 2 is applied: [29 29]\n",
            "\n",
            "\tLayer 3\n",
            "\tkernel_size:  (5, 5)\n",
            "\tSize after layer 3 is applied: [25 25]\n",
            "\n",
            "\tLayer 4\n",
            "\tkernel_size:  (5, 5)\n",
            "\tSize after layer 4 is applied: [21 21]\n",
            "\n",
            "\tLayer 5\n",
            "\tkernel_size:  (5, 5)\n",
            "\tSize after layer 5 is applied: [17 17]\n",
            "\n",
            "\tLayer 6\n",
            "\tkernel_size:  (5, 5)\n",
            "\tSize after layer 6 is applied: [13 13]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def check_input_size(size, kernel_size):\n",
        "    print(\"Input image spatial size:\",size)\n",
        "    print(\"Changes of the spatial size in the two branches (2D_cov and 3D_conv)\")\n",
        "    for i in range(2):\n",
        "        print(\"\\tLayer\",i+1)\n",
        "        print(\"\\tkernel_size: \", kernel_size[0])\n",
        "        size = np.array(size) - np.array(kernel_size[0]) + 1\n",
        "        print(\"\\tSize after layer %d is applied:\"%(i+1), size)\n",
        "        print()\n",
        "    print(\"Changes of the spatial size in the final brach:\")\n",
        "    for i in range(6):\n",
        "        print(\"\\tLayer\",i+1)\n",
        "        print(\"\\tkernel_size: \", kernel_size[2])\n",
        "        size = np.array(size) - np.array(kernel_size[2])  + 1\n",
        "        print(\"\\tSize after layer %d is applied:\"%(i+1), size)\n",
        "        print()\n",
        "\n",
        "check_input_size((size,size), kernel_size)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7 with PyTorch",
      "language": "python",
      "name": "py37"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}